This is a prototype application for RAG with LLM. It has 3 different modes:


a. PDF question-Answering (here users can upload any pdf and ask questions from it)

b. General interaction (here users can interact directly with LLM in general way)

c. Custom data help (here users can take help on some of the custom data already feeded in the application for some specific purposes)



Follow these steps to get this project running in your local system:



Step 1: Install ollama in your local system from it's official website: 'https://ollama.com/'.

Step 2: Follow the instrcutions to get the llama3 70b installed and running in your local system by running the ollama instance. Execute following command: 'ollama run llama3'.

Step 3: Create a new environment and install streamlit and PyPDF2. Ensure you have Python 3.10/3.11/3.12 only.

Step 4: Copy and Paste the file named as 'simpleChatbot1' in this environment.

Step 5: Simply run this streamlit application using the following command: 'streamlit run simplechatbot1.py'

Step 6: Interact with your chatbot in 3 different modes. (If you are running this application on a better system with more RAM and SSDs, you will get the responses much faster).


For any help or assistance, connect aalekh.rai.futurense@gmail.com
